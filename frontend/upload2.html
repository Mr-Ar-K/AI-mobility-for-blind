<!DOCTYPE html>
<html lang="en">
<head>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
  <meta charset="UTF-8">
  <title>AI Video Detection Portal</title>
  <style>
    body {
      background: #a795bc;
      margin: 0;
      font-family: Arial, sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    .main-box {
      margin-top: 40px;
      width: 430px;
      box-shadow: 0 4px 24px #1113;
      border-radius: 10px;
      overflow: hidden;
      background: none;
    }
    nav {
      display: flex;
      width: 100%;
    }
    nav button {
      flex: 1;
      border: none;
      padding: 1em 0.5em;
      color: #fff;
      font-size: 1em;
      cursor: pointer;
      outline: none;
      transition: background 0.2s;
      border-radius: 0;
      background: none;
      font-weight: bold;
    }
    .nav-upload { background: #226470; }
    .nav-detect { background: #557323; }
    .nav-live { background: #5b8edf; }
    .nav-result { background: #71357a; }

    .section-content {
      background: #19686d;
      padding: 2em;
      color: white;
      text-align: center;
      border-radius: 0 0 10px 10px;
      min-height: 340px;
    }
    .upload-btn, .live-btn {
      background: #226470;
      color: white;
      padding: 1em 2em;
      border: none;
      border-radius: 7px;
      font-size: 1.1em;
      cursor: pointer;
      margin-top: 1em;
      transition: 0.2s;
    }
    .upload-btn:hover, .live-btn:hover {
      background: #174e57;
    }
    video {
      margin-top: 1.2em;
      width: 95%;
      max-height: 240px;
      border-radius: 8px;
      box-shadow: 0 2px 8px #0003;
      background: #222;
    }
    .detections, .narration {
      margin-top: 1.4em;
      text-align: center;
    }
    .actions {
      margin-top: 1.4em;
      width: 100%;
      display: flex;
      justify-content: space-between;
      max-width: 370px;
      margin-left: auto;
      margin-right: auto;
    }
    .actions button {
      width: 46%;
      padding: 0.8em 1em;
      font-size: 1.07em;
      border-radius: 6px;
      border: none;
      cursor: pointer rys;
      color: white;
      background: #557323;
      transition: 0.2s;
    }
    .actions button:hover {
      background: #334d17;
    }
    .listening {
      color: #ffeb3b;
      font-size: 0.9em;
      margin-top: 1em;
    }
  </style>
</head>
<body>
  <div style="width:100vw; max-width:950px; margin:0 auto; display:flex; justify-content:space-between; align-items:center; position:relative; height:48px;">
    <button style="color:#444;background:none;border:none;font-size:2.2rem;cursor:pointer;padding:6px 16px 2px 16px;">
      <i class="fa-solid fa-user"></i>
    </button>
    <button style="color:#444;background:none;border:none;font-size:2.2rem;cursor:pointer;padding:6px 16px 2px 16px;">
      <i class="fa-solid fa-gear"></i>
    </button>
  </div>

  <div class="main-box">
    <nav>
      <button class="nav-upload"   onclick="showSection('upload')">Upload</button>
      <button class="nav-detect"   onclick="showSection('detect')">Results</button>
      <button class="nav-live"     onclick="showSection('live')">Live Detection</button>
      <button class="nav-result"   onclick="showSection('liveResult')">Live Results</button>
    </nav>

    <!-- ==== Upload ==== -->
    <div id="upload" class="section-content">
      <h2>Upload Video</h2>
      <p>Upload your video for object detection.</p>
      <input type="file" id="fileInput" accept="video/*" style="display:none" />
      <button id="uploadBtn" class="upload-btn">Choose Video</button>
      <div id="uploadPreview" style="display:none">
        <video id="videoPlayer" controls loop></video>
      </div>
    </div>

    <!-- ==== Detection Results ==== -->
    <div id="detect" class="section-content" style="display:none">
      <h2>Detected Objects</h2>
      <p id="detectionText">No detections yet.</p>
      <div class="detections" id="detections"></div>
      <div class="narration" id="narration"></div>
      <div class="actions" id="actions" style="display:none;">
        <button onclick="repeatNarration()">Repeat</button>
        <button onclick="downloadResults()">Download</button>
      </div>
      <div class="listening" id="listeningStatus" style="display:none;">Listening for your voice commands...</div>
    </div>

    <!-- ==== Live Detection ==== -->
    <div id="live" class="section-content" style="display:none">
      <h2>Live Video Detection</h2>
      <p>Upload or start your live video stream for detection.</p>
      <input type="file" id="liveInput" accept="video/*" style="display:none" />
      <button id="liveBtn" class="live-btn">Upload Live Video</button>
      <div id="liveVideoSection" style="display:none">
        <video id="liveVideo" controls loop></video>
        <button class="upload-btn" onclick="startLiveDetection()">Start Live Detection</button>
      </div>
    </div>

    <!-- ==== Live Results ==== -->
    <div id="liveResult" class="section-content" style="display:none">
      <h2>Live Detection Results</h2>
      <p id="liveDetectionText">Waiting for live detection results...</p>
      <div id="liveDetections"></div>
      <div id="liveNarration" class="narration"></div>
      <div class="actions">
        <button onclick="repeatLiveNarration()">Repeat</button>
        <button onclick="downloadLiveResults()">Download</button>
      </div>
    </div>
  </div>

  <script>
    // ================== GLOBALS ==================
    let recognition, isListening = false;
    let lastNarrationText = "", lastLiveNarration = "";

    // ================== SPEECH SETUP ==================
    window.onload = function () {
      setupSpeechRecognition();
      speak("This is upload section where you can upload files and get objects detection in it");
    };

    function setupSpeechRecognition() {
      if (!('webkitSpeechRecognition' in window || 'SpeechRecognition' in window)) return;
      recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
      recognition.continuous = false;
      recognition.interimResults = false;
      recognition.lang = 'en-US';

      recognition.onresult = function (e) {
        const cmd = e.results[e.results.length - 1][0].transcript.toLowerCase().trim();
        handleVoiceCommand(cmd);
      };
      recognition.onend = () => { isListening = false; updateListeningUI(false); };
    }

    function startListening() {
      if (isListening) return;
      isListening = true;
      updateListeningUI(true);
      recognition.start();
    }

    function updateListeningUI(on) {
      const status = document.getElementById('listeningStatus');
      if (!status) return;
      status.style.display = on ? 'block' : 'none';
    }

    // ================== NAVIGATION ==================
    function showSection(id) {
      document.querySelectorAll('.section-content').forEach(sec => sec.style.display = 'none');
      document.getElementById(id).style.display = 'block';
      speak(`You are in the ${id.replace(/([A-Z])/g, ' $1').toLowerCase()} section.`);
    }

    // ================== VOICE COMMAND HANDLER ==================
    function handleVoiceCommand(cmd) {
      // Global navigation
      if (cmd.includes('upload')) { showSection('upload'); return; }
      if (cmd.includes('result') || cmd.includes('detection')) { showSection('detect'); return; }
      if (cmd.includes('live') && cmd.includes('detection')) { showSection('live'); return; }
      if (cmd.includes('live') && cmd.includes('result')) { showSection('liveResult'); return; }
      if (cmd.includes('go back') || cmd.includes('home')) { showSection('upload'); return; }

      // Result-section commands (only when we are in detect)
      if (document.getElementById('detect').style.display === 'block') {
        if (cmd.includes('repeat')) { repeatNarration(); return; }
        if (cmd.includes('download')) { downloadResults(); return; }
      }

      speak('Sorry, I didn\'t understand. Try upload, results, live detection, repeat, download, or go back.');
    }

    // ================== SPEAK UTILITY ==================
    function speak(text, callback) {
      if (!('speechSynthesis' in window)) { if (callback) callback(); return; }
      const utter = new SpeechSynthesisUtterance(text);
      utter.lang = 'en-US';
      utter.rate = 1.05;
      utter.pitch = 1.1;
      utter.onend = () => {
        if (callback) callback();
      };
      window.speechSynthesis.cancel();
      window.speechSynthesis.speak(utter);
    }

    // ================== UPLOAD SECTION ==================
    const uploadBtn   = document.getElementById('uploadBtn');
    const fileInput   = document.getElementById('fileInput');
    const videoPlayer = document.getElementById('videoPlayer');
    const uploadPreview = document.getElementById('uploadPreview');

    uploadBtn.onclick = () => fileInput.click();

    fileInput.onchange = e => {
      const file = e.target.files[0];
      if (!file) return;

      videoPlayer.src = URL.createObjectURL(file);
      uploadPreview.style.display = 'block';
      speak('Processing the video....', () => {
        setTimeout(() => {
          // ---- Simulated detection ----
          const detected = ['Car', 'Person', 'Bicycle','Zebra crossing'];
          const narration = `The detections are ${detected.join(', ')}.`;

          showSection('detect');
          document.getElementById('detections').innerHTML = '<b>Detected Objects:</b> ' + detected.join(', ');
          document.getElementById('narration').innerHTML = '<b>Narration:</b> ' + narration;
          document.getElementById('actions').style.display = 'flex';
          lastNarrationText = narration;

          speak('Processing completed... ' + narration, () => {
            speak('Say repeat for repeating the detections again or say download for downloading the detections.', startListening);
          });
        }, 1500);
      });
    };

    // ================== RESULT SECTION ==================
    function repeatNarration() {
      speak(lastNarrationText);
    }

    function downloadResults() {
      // In a real app you would create a Blob/JSON and trigger download
      speak('Results downloaded successfully.');
    }

    // ================== LIVE DETECTION ==================
    const liveBtn = document.getElementById('liveBtn');
    const liveInput = document.getElementById('liveInput');
    const liveVideo = document.getElementById('liveVideo');
    const liveVideoSection = document.getElementById('liveVideoSection');

    liveBtn.onclick = () => liveInput.click();
    liveInput.onchange = e => {
      const file = e.target.files[0];
      if (file) {
        liveVideo.src = URL.createObjectURL(file);
        liveVideoSection.style.display = 'block';
        speak('Live video uploaded. Click start live detection to proceed.');
      }
    };

    function startLiveDetection() {
      showSection('liveResult');
      const detected = ['Car', 'Bicycle','Person','Car'];
      const liveNarr = `In live detection, we found a ${detected.join(' and a ')}.`;
      document.getElementById('liveDetections').innerHTML = '<b>Detected in Live Feed:</b> ' + detected.join(', ');
      document.getElementById('liveNarration').innerHTML = '<b>Narration:</b> ' + liveNarr;
      lastLiveNarration = liveNarr;
      speak(liveNarr);
    }

    function repeatLiveNarration() { speak(lastLiveNarration); }
    function downloadLiveResults() { speak('Live detection results downloaded successfully.'); }
  </script>
</body>
</html>